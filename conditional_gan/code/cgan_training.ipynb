{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:53:15.221343Z",
     "start_time": "2020-08-07T19:53:15.214596Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pickle\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical, plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:53:31.790848Z",
     "start_time": "2020-08-09T17:53:31.788289Z"
    }
   },
   "outputs": [],
   "source": [
    "weights_path = '../weights/'\n",
    "data_path='../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:53:25.583513Z",
     "start_time": "2020-08-07T19:53:25.573512Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(48,48,1), n_classes=7):\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # scale up to image dimensions with linear activation\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "    # image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "    # concat label as a channel\n",
    "    merge = Concatenate()([in_image, li])\n",
    "    \n",
    "    be = Conv2D(32, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    be = LeakyReLU(alpha=0.2)(be)\n",
    "    ce = Conv2D(64, (3,3), strides=(2,2), padding='same')(be)\n",
    "    ce = LeakyReLU(alpha=0.2)(ce)\n",
    "    fe = Conv2D(128, (3,3), padding='same')(ce)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = Conv2D(128, (3,3), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = Flatten()(fe)    \n",
    "    fe = Dropout(0.2)(fe)\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "    \n",
    "    model = Model([in_image, in_label], out_layer)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:53:26.318779Z",
     "start_time": "2020-08-07T19:53:26.196603Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m                 \u001b[0mworking_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     prog=prog)\n\u001b[0;32m-> 1922\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-adeeb0a1270a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefine_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         raise OSError(\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[0;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "plot_model(define_discriminator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:40:13.414071Z",
     "start_time": "2020-08-06T19:40:13.295028Z"
    }
   },
   "source": [
    "## Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:40:13.426438Z",
     "start_time": "2020-08-06T19:40:13.418212Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_generator(latent_dim, n_classes=7):\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    n_nodes = 12 * 12\n",
    "    li = Dense(n_nodes)(li)\n",
    "    li = Reshape((12, 12, 1))(li)\n",
    "    \n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    n_nodes = 128 * 12 * 12\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((12, 12, 128))(gen)\n",
    "    \n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate()([gen, li]) #(None, 12, 12, 129)\n",
    "    \n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)    \n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    out_layer = Conv2D(1, (12,12), activation='tanh', padding='same')(gen)\n",
    "    \n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:54:14.731134Z",
     "start_time": "2020-08-09T17:54:14.559463Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-cde785dee974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdefine_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'define_generator' is not defined"
     ]
    }
   ],
   "source": [
    "define_generator(100).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:40:13.522734Z",
     "start_time": "2020-08-06T19:40:13.517882Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    \n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load real samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T17:23:01.794890Z",
     "start_time": "2020-08-07T17:23:01.790680Z"
    }
   },
   "outputs": [],
   "source": [
    "# load face images\n",
    "def load_real_samples():\n",
    "   \n",
    "    trainX=pickle.load(open(data_path+'trainX.pkl', 'rb'))\n",
    "    trainy=pickle.load(open(data_path+'trainy.pkl', 'rb'))\n",
    "    \n",
    "    trainX = expand_dims(trainX, axis=-1)\n",
    "    trainX = trainX.astype('float32')\n",
    "    trainX = (trainX - 127.5) / 127.5\n",
    "    return [trainX, trainy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:40:13.753430Z",
     "start_time": "2020-08-06T19:40:13.749370Z"
    }
   },
   "outputs": [],
   "source": [
    "# # select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    images, labels = dataset\n",
    "    index = randint(0, images.shape[0], n_samples)\n",
    "    X, labels = images[index], labels[index]\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:40:15.267047Z",
     "start_time": "2020-08-06T19:40:15.263069Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples, n_classes=7):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:55:47.286738Z",
     "start_time": "2020-08-09T17:55:47.269778Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:56:00.283008Z",
     "start_time": "2020-08-09T17:56:00.277779Z"
    }
   },
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(dloss1,dloss2,gloss,accuracy):\n",
    "    clear_output(wait=True)\n",
    "    plt.style.use(\"seaborn\")\n",
    "\n",
    "    epochs = range(len(dloss1))\n",
    "    pltdloss1_x = [index for index,i in enumerate(dloss1) if i<2 ]\n",
    "    pltdloss1_y = [i for i in dloss1 if i<2 ]\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(pltdloss1_x, pltdloss1_y, 'bo', label='Loss on real images')\n",
    "\n",
    "    pltdloss2_x = [index for index,i in enumerate(dloss2) if i<2 ]\n",
    "    pltdloss2_y = [i for i in dloss2 if i<2 ]\n",
    "    plt.plot(pltdloss2_x, pltdloss2_y, 'ro', label='Loss on fake images')\n",
    "    plt.title('Loss plots for Discriminator and Generator')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(epochs, gloss, 'r')\n",
    "    plt.title('Loss plot for CGAN, with min(loss):'+ str(round(min(gloss),2))+' for epoch:'+str(np.argmax(gloss)))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(epochs, accuracy, 'g', label='Accuracy GAN')\n",
    "    plt.title('Accuracy plot for CGAN, with max(acc):'+ str(round(max(accuracy),2))+' for epoch:'+str(np.argmax(accuracy)))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:40:17.335112Z",
     "start_time": "2020-08-06T19:40:17.322527Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=512):\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    dloss1 = []\n",
    "    dloss2 = []\n",
    "    gloss = []\n",
    "    accuracy = []\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        print('Epoch {}'.format(i))\n",
    "        # enumerate batches over the training set\n",
    "        tot_dloss1=0\n",
    "        tot_dloss2=0\n",
    "        tot_gloss=0\n",
    "        tot_acc=0\n",
    "        for j in notebook.tqdm(range(bat_per_epo)):\n",
    "            # select a random half_batch of real images\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)      \n",
    "            # generate a half_batch of \"fake\" images\n",
    "            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            \n",
    "            # update discriminator model weights \n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real) \n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "            \n",
    "            # prepare points in latent space as input for the generator\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            \n",
    "            tot_dloss1+=d_loss1\n",
    "            tot_dloss2+=d_loss2\n",
    "            tot_gloss+=g_loss[0]\n",
    "            tot_acc+=g_loss[1]\n",
    "\n",
    "        dloss1.append(tot_dloss1/bat_per_epo)\n",
    "        dloss2.append(tot_dloss2/bat_per_epo)\n",
    "        gloss.append(tot_gloss/bat_per_epo)\n",
    "        accuracy.append(tot_acc/bat_per_epo)\n",
    "            \n",
    "        # save the generator model every 5th epoch\n",
    "        if i%5==0:\n",
    "            g_model.save(weights_path+'cgan_epoch{}.h5'.format(i))\n",
    "            \n",
    "    g_model.save(weights_path+'cgan_epoch{}.h5'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-06T19:40:22.885Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f772dce6c4834c1eb0b009fad62513c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172a6dcf88d147d4bbbe292337c165c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "dataset = load_real_samples()\n",
    "train(g_model, \n",
    "      d_model, \n",
    "      gan_model, \n",
    "      dataset, \n",
    "      latent_dim,\n",
    "      n_epochs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REFERENCES\n",
    "1. https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
